# Streaming Speech-to-Text with WebSocket

Stream audio in real-time and receive instant transcriptions with Waves ASR.

---

## Overview

The Waves Streaming STT API enables real-time speech-to-text transcription over WebSocket connections. Stream audio from microphones, files, or telephony systems and receive transcriptions as users speak‚Äîperfect for voice assistants, live captioning, and conversational AI applications.

**Endpoint:** `wss://waves-api.smallest.ai/api/v1/asr`

**Method:** WebSocket Connection

**Pricing:** $0.025 per minute (billed per second)

---

## Authentication

Include your API key as a query parameter in the WebSocket URL:

```
wss://waves-api.smallest.ai/api/v1/asr?api_key=YOUR_API_KEY
```

<Warning>
Streaming STT requires an **Enterprise Monthly** or **Enterprise Yearly** subscription.
</Warning>

---

## Required Parameters

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `api_key` | string | Your Waves API key | `sk_test_abc123...` |
| `audioEncoding` | string | Audio format | `linear16`, `flac`, `mulaw`, `opus` |
| `audioSampleRate` | string | Sample rate in Hz | `16000` (recommended) |
| `audioChannels` | string | Number of audio channels | `1` (mono) |

---

## Optional Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `audioLanguage` | string | `en` | Language code (`en`, `hi`, `es`, `fr`, etc.) |
| `addPunctuation` | boolean | `false` | Automatically add punctuation |
| `speechEndpointing` | integer | `300` | Silence duration (ms) to mark turn end |

<Tip>
Use `16000` Hz sample rate for optimal balance between quality and performance. For telephony applications, `8000` Hz is standard.
</Tip>

---

## Quick Start Example

### Python WebSocket Streaming

```python
import asyncio
import websockets
import json

async def transcribe_audio():
    # Configure connection parameters
    params = {
        "api_key": "YOUR_API_KEY",
        "audioEncoding": "linear16",
        "audioSampleRate": "16000",
        "audioChannels": "1",
        "audioLanguage": "en",
        "addPunctuation": "true"
    }
    
    # Build WebSocket URL
    query = "&".join([f"{k}={v}" for k, v in params.items()])
    url = f"wss://waves-api.smallest.ai/api/v1/asr?{query}"
    
    # Connect to WebSocket
    async with websockets.connect(url) as ws:
        print("‚úÖ Connected to Waves STT")
        
        # Read audio file
        with open("audio.wav", "rb") as f:
            audio_data = f.read()
        
        # Stream audio in chunks (100ms chunks for 16kHz)
        # Formula: sample_rate * bytes_per_sample * duration
        chunk_size = int(16000 * 2 * 0.1)  # 3,200 bytes
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            await ws.send(chunk)
            
            # Listen for responses (non-blocking)
            try:
                response = await asyncio.wait_for(ws.recv(), timeout=0.01)
                result = json.loads(response)
                
                if "text" in result:
                    end_marker = " [END]" if result.get("isEndOfTurn") else ""
                    print(f"üìù {result['text']}{end_marker}")
                    
            except asyncio.TimeoutError:
                continue
        
        # Signal end of stream
        await ws.send(b'')
        print("‚úÖ Streaming complete")
        
        # Collect remaining responses
        async for message in ws:
            result = json.loads(message)
            if "text" in result:
                print(f"üìù Final: {result['text']}")

# Run the transcription
asyncio.run(transcribe_audio())
```

---

## Response Format

### Transcription Response

```json
{
  "text": "Hello, this is a test transcription.",
  "isEndOfTurn": false
}
```

**Response Fields:**
- `text` (string) - The transcribed text segment
- `isEndOfTurn` (boolean) - `true` when silence threshold is reached, indicating the speaker has finished

### Error Response

```json
{
  "error": "Invalid audio format",
  "code": "AUDIO_FORMAT_ERROR"
}
```

---

## Best Practices

### 1. Optimal Chunking Strategy

Stream audio in **100-300ms chunks** for best latency:

- **16 kHz audio:** 3,200 - 9,600 bytes per chunk
- **8 kHz audio:** 1,600 - 4,800 bytes per chunk
- **Formula:** `sample_rate √ó 2 √ó duration_in_seconds`

### 2. End-of-Stream Signal

Always send an empty binary message when finished:

```python
await ws.send(b'')  # Flushes remaining audio from buffer
```

### 3. Sample Rate Matching

Ensure your audio's actual sample rate matches the `audioSampleRate` parameter. Mismatched rates cause poor transcription quality.

### 4. Error Handling

Implement proper error handling for network issues:

```python
try:
    async with websockets.connect(url) as ws:
        # Your streaming code
except websockets.exceptions.ConnectionClosed:
    print("Connection closed unexpectedly")
except Exception as e:
    print(f"Error: {e}")
```

---

## Supported Languages

Waves STT supports **30+ languages** including:

| Language | Code | Language | Code |
|----------|------|----------|------|
| English | `en` | Hindi | `hi` |
| Spanish | `es` | French | `fr` |
| German | `de` | Russian | `ru` |
| Portuguese | `pt` | Japanese | `ja` |
| Italian | `it` | Dutch | `nl` |

<Info>
For the complete language list and availability, see the [full API documentation](https://waves-docs.smallest.ai).
</Info>

---

## Audio Format Support

| Format | Description | Best For |
|--------|-------------|----------|
| `linear16` | 16-bit linear PCM (recommended) | High quality, general use |
| `flac` | FLAC compressed | Compressed audio files |
| `mulaw` | Œº-law encoded | Telephony applications |
| `opus` | Opus compressed | Browser-native formats |

---

## Common Issues

**Problem:** Poor transcription accuracy

**Solutions:**
- Verify sample rate matches audio file
- Use `linear16` encoding for best quality
- Ensure mono audio (`audioChannels: "1"`)
- Enable punctuation for better readability

**Problem:** High latency

**Solutions:**
- Reduce chunk size to 100ms
- Use lower sample rate (8kHz for telephony)
- Check network connection quality

---

## Need Help?

- **Documentation:** [https://waves-docs.smallest.ai](https://waves-docs.smallest.ai)
- **API Status:** Check service status and uptime
- **Support:** Contact support for Enterprise customers